{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도가 향상된 이미지 분류기 만들기\n",
    "\n",
    "이전주차보다 신경망의 정확도를 향상시키는 것을 목표로 한다. 신경망을 정의하는 부분에서 변화를 주어 여러가지 방법으로 접근해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 주차에 사용했던 CIFAR-10 데이터셋을 사용한다. CIFAR-10에 포함된 이미지의 크기는 3x32x32로, 이는 32x32 픽셀 크기의 이미지가 3개 채널(channel)의 색상로 이뤄져 있다는 것을 의미한다.\n",
    "\n",
    "다음과 같은 단계로 학습한다.\n",
    "\n",
    "1. torchvision 을 사용하여 CIFAR-10의 학습(training), 평가(test) 데이터셋을 로드하여 정규화(nomarlizing)한다.\n",
    "\n",
    "2. 합성곱 신경망(Convolution Neural Network)을 정의한다.\n",
    "\n",
    "3. 손실 함수를 정의한다.\n",
    "\n",
    "4. 학습용 데이터를 사용하여 신경망을 학습시킨다.\n",
    "\n",
    "5. 시험용 데이터를 사용하여 신경망을 검사한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1단계 : CIFAR-10 로딩 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2~4 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.990\n",
      "[1,  4000] loss: 1.748\n",
      "[1,  6000] loss: 1.666\n",
      "[1,  8000] loss: 1.620\n",
      "[1, 10000] loss: 1.572\n",
      "[1, 12000] loss: 1.569\n",
      "[2,  2000] loss: 1.492\n",
      "[2,  4000] loss: 1.485\n",
      "[2,  6000] loss: 1.460\n",
      "[2,  8000] loss: 1.428\n",
      "[2, 10000] loss: 1.411\n",
      "[2, 12000] loss: 1.411\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # First 2D convolutional layer, taking in 3 input channels (image)\n",
    "        # 6 output channels, a square kernel size of 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # Max pooling over a (2, 2) mask\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second 2D convolutional layer, taking in 6 input layers,\n",
    "        # 16 output channels, a square kernel size of 5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 256) # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(256, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        # Pass data through conv1\n",
    "        # Use the rectified-linear activation function over x\n",
    "        # Run max pooling over x\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Pass data through conv1\n",
    "        # Use the rectified-linear activation function over x\n",
    "        # Run max pooling over x\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(2):   # 데이터셋을 수차례 반복\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 순전파\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        #변화도를 0으로 만들고, 역전파 단계를 수행 후 가중치 갱신\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (t + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0        \n",
    "        \n",
    "    \n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 시험용 데이터로 신경망 검사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch37",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
